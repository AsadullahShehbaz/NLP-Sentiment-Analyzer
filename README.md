
# ğŸ¬ Production-Ready NLP Sentiment Analysis System

A **production-oriented NLP application** for movie review sentiment analysis using a **fine-tuned DistilBERT model**, deployed with **Streamlit** and built following **clean ML engineering practices**.

This project demonstrates **real-world ML inference**, **model caching**, **structured logging**, and **interactive visualization**, making it suitable for **ML Engineer / NLP Engineer roles**.

---

## ğŸš€ Demo Features

- âœ… Fine-tuned **DistilBERT** for binary sentiment classification
- âœ… Production-grade **Streamlit UI**
- âœ… Model caching for fast inference
- âœ… Confidence-aware predictions
- âœ… Probability visualization with Plotly
- âœ… Structured logging for debugging & monitoring
- âœ… Clean separation of UI and inference logic

---

## ğŸ§  Model Details

| Component | Description |
|---------|------------|
| Model | DistilBERT (fine-tuned) |
| Dataset | IMDB Movie Reviews |
| Task | Binary Sentiment Classification |
| Framework | PyTorch + HuggingFace |
| Accuracy | ~86.25% |
| Max Length | 512 tokens |

Model hosted on HuggingFace Hub:
```

asadullahshehbaz/my_text_classifier_model

```

---

## ğŸ—‚ï¸ Project Structure

```

.
â”œâ”€â”€ app.py                # Streamlit frontend (UI only)
â”œâ”€â”€ main.py               # Model loading & inference logic
â”œâ”€â”€ logg.py               # Centralized logging configuration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

**Design Principle:**  
> UI and ML logic are intentionally separated to reflect production ML systems.

---

## ğŸ–¥ï¸ Application Flow

1. User enters a movie review
2. Text is tokenized using HuggingFace tokenizer
3. DistilBERT performs inference
4. Softmax probabilities are computed
5. Sentiment + confidence score returned
6. Results visualized in an interactive bar chart

---

## ğŸ“Š Output Example

- **Sentiment:** Positive ğŸ˜Š / Negative ğŸ˜
- **Confidence:** Probability of predicted class
- **Visualization:** Probability distribution (Positive vs Negative)

Low-confidence predictions can be easily flagged in future iterations.

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/asadullahshehbaz/nlp-sentiment-analyzer.git
cd imdb-sentiment-analyzer
````

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the app

```bash
streamlit run app.py
```

---

## ğŸ§ª Inference Logic (Simplified)

```python
with torch.no_grad():
    outputs = model(**inputs)
    probs = softmax(outputs.logits)
```

Confidence is computed as:

```python
confidence = max(positive_prob, negative_prob)
```

---

## ğŸ“ˆ Engineering Highlights (Why This Is Production-Ready)

âœ” Model caching using `@st.cache_resource`
âœ” Clean inference abstraction
âœ” Structured logging with severity levels
âœ” Error-safe inference handling
âœ” Production-friendly UI
âœ” Extendable for API / batch inference

---

## âš ï¸ Limitations

* Single-sentence inference only
* No explainability (SHAP / LIME) yet
* CPU inference (no GPU optimization)
* No batch processing in UI

---

## ğŸ”® Future Improvements

* ğŸ” Add SHAP / LIME explainability
* ğŸš€ FastAPI backend for REST inference
* ğŸ“¦ Dockerization
* ğŸ“Š Batch inference support
* ğŸ§ª Unit tests for inference
* â˜ï¸ Cloud deployment (AWS / GCP / Railway)

---

## ğŸ‘¨â€ğŸ’» Author

**Asadullah Shehbaz**
Machine Learning & NLP Engineer

* Kaggle Master
* PyTorch & HuggingFace Specialist
* Focused on production-grade AI systems

---

## â­ Why This Project Matters

This is **not a notebook demo**.
It reflects **real ML deployment thinking**, suitable for:

* NLP Engineer roles
* ML Engineer roles
* AI Engineer portfolios
* Freelance ML projects

---

## ğŸ“œ License

MIT License



